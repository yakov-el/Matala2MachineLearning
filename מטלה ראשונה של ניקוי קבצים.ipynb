{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e21a69-aaff-4afa-9821-f601e20e78a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59dae8d8-c79b-4539-8918-38aa8ffbf4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def isnat(x):\n",
    "    return x.astype('i8') == np.datetime64('NaT').astype('i8')\n",
    "\n",
    "def clean_white_space(data):\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        ind = 0 \n",
    "        for g in data.iloc[i] :\n",
    "            try:\n",
    "                g = g.split()\n",
    "                if g == []:\n",
    "                    data.iloc[i,ind]= np.nan\n",
    "                ind = ind +1\n",
    "            except:\n",
    "                ind = ind +1\n",
    "                pass\n",
    "\n",
    "    return (data)\n",
    "\n",
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    \n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def check_types(new_data):\n",
    "    \n",
    "    marks = {}.fromkeys(['to_numeric', 'to_string','null','boolean','to_datetime'], 0)\n",
    "\n",
    "    for index in range(len(new_data)):\n",
    "        \n",
    "        row = new_data[index]\n",
    "        \n",
    "        if ((isfloat(row)) &  (pd.isna(row)is False)):\n",
    "             row=float(row)\n",
    "             new_data[index]=row\n",
    "             marks['to_numeric'] += 1\n",
    "                          \n",
    "        if isinstance(row,str):\n",
    "            if (((row.lower() == 'true') | (row.lower() == 'false'))is False):\n",
    "                    try:\n",
    "                        new_data[index]=pd.to_datetime(row)\n",
    "                        if isinstance(row, pd._libs.tslibs.nattype.NaTType):\n",
    "                            print('row')\n",
    "                            new_data[index] = np.nan()\n",
    "                        marks['to_datetime'] += 1\n",
    "                \n",
    "                    except:\n",
    "                          marks['to_string'] += 1\n",
    "                     \n",
    "            elif (row.lower() == 'true') | (row.lower() == 'false'):\n",
    "                     marks['boolean'] += 1                  \n",
    "                \n",
    "        if pd.isna(row):\n",
    "                marks['null'] += 1            \n",
    "                        \n",
    "    print(marks)\n",
    "    return(marks)\n",
    "\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set() # Set of all the names of deleted columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j] >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
    "                colname = corr_matrix.columns[i] # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "                if colname in dataset.columns:\n",
    "                    del dataset[colname] # deleting the column from the dataset\n",
    "\n",
    "    return(dataset)\n",
    "\n",
    "def DataCleaning(data):\n",
    "    # בדיקה אם יש white space\n",
    "    data = clean_white_space(data)\n",
    "    # בדיקה אם יש עמודה רק של ערכי null והורדה של אחת כזו\n",
    "    cols_to_check = data.columns\n",
    "    data['is_na'] = data[cols_to_check].isnull().apply(lambda x: all(x), axis=1) \n",
    "    data = data[data.is_na==False]\n",
    "    data=data.drop('is_na',axis = 1)\n",
    "    # הורדה של שורות אותו דבר\n",
    "    data = data.drop_duplicates()\n",
    "    nunique = data.nunique()\n",
    "    cols_to_drop = nunique[nunique == 1].index\n",
    "    data = data.drop(cols_to_drop, axis=1)\n",
    "    data=data[data.columns[data.isnull().mean() < 0.80]]\n",
    "    data=data.reset_index()\n",
    "    data=data.drop('index',axis = 1)\n",
    "\n",
    "    num_to_impute = []\n",
    "    not_drop = []\n",
    "    for i in data:\n",
    "        new_data = data.loc[:,i]\n",
    "        marks = check_types(new_data)\n",
    "        warnings.filterwarnings('ignore')\n",
    "        max_key = max(marks, key=marks.get)\n",
    "\n",
    "        if max_key == 'to_numeric':\n",
    "            data.loc[:,i]=pd.to_numeric(data.loc[:,i], errors='coerce')\n",
    "\n",
    "            if new_data.isnull().mean() >= 0.8:\n",
    "                data=data.drop(i , axis = 1)\n",
    "\n",
    "            else:\n",
    "                num_to_impute.append(i)\n",
    "\n",
    "        if max_key == 'to_datetime':\n",
    "            data.loc[:,i]=pd.to_datetime(data.loc[:,i], errors='coerce')\n",
    "\n",
    "            if (1-(new_data.value_counts().sum()/len(new_data))) >= 0.8:\n",
    "                data=data.drop(i , axis = 1)\n",
    "            else:\n",
    "                data.loc[:,i] = data.loc[:,i].fillna(data.loc[:,i].value_counts().index[0])\n",
    "                not_drop.append(i)\n",
    "        elif   max_key == 'to_string': \n",
    "            data.loc[:,i].to_string()\n",
    "            data.loc[:,i] = data.loc[:,i].fillna(data.loc[:,i].value_counts().index[0])\n",
    "\n",
    "        if  max_key == 'boolean':\n",
    "            data.loc[:,i]=data.loc[:,i].astype('bool')\n",
    "\n",
    "            if new_data.isnull().mean() >= 0.8:\n",
    "                data=data.drop(i , axis = 1)\n",
    "            else:\n",
    "                data.loc[:,i] = data.loc[:,i].fillna(data.loc[:,i].value_counts().index[0])\n",
    "                not_drop.append(i)\n",
    "        if (new_data.nunique()/len(new_data))<=0.14:\n",
    "            data.loc[:,i]=data.loc[:,i].astype(\"category\")\n",
    "            data.loc[:,i] = data.loc[:,i].fillna(data.loc[:,i].value_counts().index[0])\n",
    "        print(max_key)\n",
    "    data\n",
    "\n",
    "    imputer = SimpleImputer(missing_values = np.nan, strategy = 'median')\n",
    "    imputer = imputer.fit(data.loc[:,num_to_impute])\n",
    "    data.loc[:,num_to_impute] = imputer.transform(data.loc[:,num_to_impute])\n",
    "    scaler = MinMaxScaler()\n",
    "    data.loc[:,num_to_impute] = scaler.fit_transform(data.loc[:,num_to_impute])\n",
    "    y=data.loc[:,not_drop]\n",
    "    X=data.drop(num_to_impute, axis = 1)\n",
    "    df1=pd.get_dummies(X,drop_first=True)\n",
    "    data=pd.concat([df1,data],axis=1)\n",
    "    new_to_drop = []\n",
    "    data.drop(X.columns,axis=1,inplace=True)\n",
    "    data=pd.concat([y,data],axis=1)\n",
    "    data = correlation(data,0.9)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "9ef4dac6-2644-490a-a1c2-3aa29faf27d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a48d1a-5668-42ca-806d-d152b8f49d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
